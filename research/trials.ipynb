{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3c7a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc358e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_API_ENV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de170c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the data\n",
    "def load_data(file_path):\n",
    "    loader = DirectoryLoader(file_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11995d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_data(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa37eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Traction\\nTraditional Chinese medicine\\nTrager psychophysical integration\\nTranscranial Doppler\\nultrasonography\\nTransesophageal echocardiography\\nTransfusion\\nTranshepatic biliary catheterization\\nTransient ischemic attack\\nTransposition of the great arteries\\nTransurethral bladder resection\\nTransvaginal ultrasound\\nTransverse myelitis\\nTraumatic amputations\\nTravelerâ€™s diarrhea\\nTremors\\nTrench fever\\nTrichinosis\\nTrichomoniasis\\nTricuspid valve insufficiency\\nTricuspid valve stenosis\\nTrigeminal neuralgia\\nTrigg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[20].page_content[:500]  # Display first 500 characters of the 21st document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7804d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text chunks\n",
    "def create_text_chunks(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46488aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 40000\n"
     ]
    }
   ],
   "source": [
    "text_chunks = create_text_chunks(extracted_data)\n",
    "print(f\"Number of text chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73320e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n2\\nC-F\\nJACQUELINE L. LONGE, PROJECT EDITOR'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bd686af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dowload embedding model\n",
    "def get_embedding_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06afd71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72a3b56dbe0469dbb45e5dab0cd4de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namankukreti\\OneDrive - Nagarro\\Desktop\\GenAI\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\namankukreti\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb26dd0c3f847bb98b5072073875d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8c4e0ab96e470d948e200110e08d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b6f90ce41c49f1ad3712960286f6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51aa642b9734d008197525c7bb703d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740ff50a9291463ba25d4e4b5e1a4b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb62c9fc7e947c7b86c0d440e1a29cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145e0217849440df9cf87c1b0b0c110e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bb289ccad042fcba34979510e2c229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117c35860a2e4fe5ad7097767bffe6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bed1a7cffde413d8f2a89ae012b43fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = get_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64d26915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='all-MiniLM-L12-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d163f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "637cd06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namankukreti\\AppData\\Local\\Temp\\ipykernel_26372\\3007376421.py:6: RuntimeWarning: coroutine 'PineconeVectorStore.afrom_texts' was never awaited\n",
      "  docsearch = PineconeVectorStore.from_documents(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_API_ENV\n",
    ")\n",
    "index_name = \"medchat\"\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    pinecone_api_key=PINECONE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "761f1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b39c643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_5sy1oR_6mRmG3eL9XMVfhf6Q5oJw7LeMwhA4b8SiKFhK2NFp7jS7C6hccR1nMzmwgF999c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10013dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result triggered by harmless, everyday substances. This is\n",
      "the condition known as allergy, and the offending\n",
      "substance is called an allergen. Common inhaled\n",
      "allergens include pollen,dust, and insect parts from\n",
      "tiny house mites. Common food allergens include\n",
      "nuts, fish, and milk.\n",
      "Allergic reactions involve a special set of cells\n",
      "in the immune system known as mast cells. Mast\n",
      "cells serve as guards in the tissues where the body\n",
      "meets the outside world: the skin, the mucous\n"
     ]
    }
   ],
   "source": [
    "docsearch=PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings)\n",
    "\n",
    "query = \"What are allergies\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"result\", docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3cf5ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "You are a helpful medical assistant. \n",
    "Use the following context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer and nothing else.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ba2588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f378061",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\", \n",
    "    model_type=\"llama\", \n",
    "    config={\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_new_tokens\": 512,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a82ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\":2}),\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6785aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namankukreti\\AppData\\Local\\Temp\\ipykernel_26372\\2575370938.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result=qa({\"query\": user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Helpful Answer:\n",
      " Acne is a skin condition that occurs when new skin cells are laid down to replace damaged cells. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(\"Ask a medical question (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"\\nHelpful Answer:\\n\", result['result'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868798d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
